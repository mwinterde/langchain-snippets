{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import inspect"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Basics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.prompts import (\n",
    "    ChatPromptTemplate, \n",
    "    HumanMessagePromptTemplate, \n",
    "    AIMessagePromptTemplate, \n",
    "    SystemMessagePromptTemplate\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`ChatPromptTemplate` is the base class for all chat prompts\n",
    "\n",
    "It is constructed with a list of message prompt templates (`HumanMessagePromptTemplate`, `AIMessagePromptTemplate`, `SystemMessagePromptTemplate`)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatPromptTemplate(input_variables=['target_language', 'input', 'source_language'], output_parser=None, partial_variables={}, messages=[SystemMessagePromptTemplate(prompt=PromptTemplate(input_variables=['source_language', 'target_language'], output_parser=None, partial_variables={}, template='Your are a translator. Given a user input in {source_language}, translate it into {target_language}.', template_format='f-string', validate_template=True), additional_kwargs={}), HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['input'], output_parser=None, partial_variables={}, template='{input}', template_format='f-string', validate_template=True), additional_kwargs={})])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Most convenient way to setup a chat prompt template: \n",
    "# 1. use `from_template` for creating message prompt templates\n",
    "# 2. use `from_messages` for creating final chat prompt template\n",
    "\n",
    "# Create system message prompt template\n",
    "system_message_template = \"Your are a translator. Given a user input in {source_language}, translate it into {target_language}.\"\n",
    "system_message_prompt_template = SystemMessagePromptTemplate.from_template(system_message_template)\n",
    "\n",
    "# Create human message prompt template\n",
    "human_message_template = \"{input}\"\n",
    "human_message_prompt_template = HumanMessagePromptTemplate.from_template(human_message_template)\n",
    "\n",
    "# Create chat prompt template\n",
    "chat_prompt_template = ChatPromptTemplate.from_messages([system_message_prompt_template, human_message_prompt_template])\n",
    "chat_prompt_template"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'System: Your are a translator. Given a user input in English, translate it into French.\\nHuman: Hello, how are you?'"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create prompt from prompt template\n",
    "chat_prompt = chat_prompt_template.format(source_language=\"English\", target_language=\"French\", input=\"Hello, how are you?\")\n",
    "chat_prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatPromptValue(messages=[SystemMessage(content='Your are a translator. Given a user input in English, translate it into French.', additional_kwargs={}), HumanMessage(content='Hello, how are you?', additional_kwargs={}, example=False)])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# `format` directly converts the prompt template into a string, therefore for chat prompt templates,\n",
    "# it may be more practical to first use the  `format_prompt` method, and then create the output format\n",
    "# we want based on the resulting `ChatPromptValue` object \n",
    "chat_prompt = chat_prompt_template.format_prompt(source_language=\"English\", target_language=\"French\", input=\"Hello, how are you?\")\n",
    "chat_prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[SystemMessage(content='Your are a translator. Given a user input in English, translate it into French.', additional_kwargs={}),\n",
       " HumanMessage(content='Hello, how are you?', additional_kwargs={}, example=False)]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# i.e. a list of messages using the `to_messages` method\n",
    "chat_prompt.to_messages()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'System: Your are a translator. Given a user input in English, translate it into French.\\nHuman: Hello, how are you?'"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# i.e. a list of messages using the `to_string` method --> similar to if we had used `format` directly\n",
    "chat_prompt.to_string()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SystemMessagePromptTemplate(prompt=PromptTemplate(input_variables=['source_language', 'target_language'], output_parser=None, partial_variables={}, template='Your are a translator. Given a user input in {source_language}, translate it into {target_language}.', template_format='f-string', validate_template=True), additional_kwargs={})"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# If we want to create a message prompt template without using the `from_template` method, we need to\n",
    "# create a PromptTemplate object first, and then pass it to the constructor of the message prompt template\n",
    "from langchain.prompts import PromptTemplate\n",
    "\n",
    "prompt_template = PromptTemplate(\n",
    "    template=\"Your are a translator. Given a user input in {source_language}, translate it into {target_language}.\",\n",
    "    input_variables=[\"source_language\", \"target_language\"]\n",
    ")\n",
    "system_message_prompt_template = SystemMessagePromptTemplate(prompt=prompt_template)\n",
    "system_message_prompt_template"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatPromptTemplate(input_variables=['source_language', 'target_language', 'input'], output_parser=None, partial_variables={}, messages=[SystemMessagePromptTemplate(prompt=PromptTemplate(input_variables=['source_language', 'target_language'], output_parser=None, partial_variables={}, template='Your are a translator. Given a user input in {source_language}, translate it into {target_language}.', template_format='f-string', validate_template=True), additional_kwargs={}), HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['input'], output_parser=None, partial_variables={}, template='{input}', template_format='f-string', validate_template=True), additional_kwargs={})])"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# If we want to create a chat prompt template without using the `from_messages` method, we need to\n",
    "# pass a list of message prompt templates and a list of input variables to the constructor of the chat \n",
    "# prompt template\n",
    "chat_prompt_template = ChatPromptTemplate(\n",
    "    messages=[system_message_prompt_template, human_message_prompt_template],\n",
    "    input_variables=[\"source_language\", \"target_language\", \"input\"]\n",
    ")\n",
    "chat_prompt_template"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ˜¢\n"
     ]
    }
   ],
   "source": [
    "# Some of the methods that are available for standard LLM models are not yet available \n",
    "# for chat models, i.e. partial formatting\n",
    "try:\n",
    "    chat_prompt_template.partial(source_language=\"English\", target_language=\"French\")\n",
    "except NotImplementedError as e:\n",
    "    print(\"ðŸ˜¢\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Message Placeholders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.prompts import MessagesPlaceholder\n",
    "from langchain.schema import HumanMessage, AIMessage"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Message placeholders are a very powerful idea that makes prompting for chat models much more flexible"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatPromptTemplate(input_variables=['conversation', 'num_sentences'], output_parser=None, partial_variables={}, messages=[MessagesPlaceholder(variable_name='conversation'), HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['num_sentences'], output_parser=None, partial_variables={}, template='Summarize the previous conversation in {num_sentences} sentences.', template_format='f-string', validate_template=True), additional_kwargs={})])"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "human_message_template = \"Summarize the previous conversation in {num_sentences} sentences.\"\n",
    "human_message_prompt_template = HumanMessagePromptTemplate.from_template(human_message_template)\n",
    "chat_prompt_template = ChatPromptTemplate.from_messages(\n",
    "    messages=[MessagesPlaceholder(variable_name=\"conversation\"), human_message_prompt_template]\n",
    ")\n",
    "chat_prompt_template"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AI: Hi, I am your personal assistant. How can I help you?\n",
      "Human: I would like to book a flight to Paris.\n",
      "AI: Sure, when would you like to travel?\n",
      "Human: Next week.\n",
      "AI: Great, I found a flight for you. Do you want to book it?\n",
      "Human: Yes, please.\n",
      "AI: Done. Your flight is booked.\n",
      "Human: Summarize the previous conversation in 2 sentences.\n"
     ]
    }
   ],
   "source": [
    "chat_prompt_value = chat_prompt_template.format_prompt(\n",
    "    conversation=[\n",
    "        AIMessage(content=\"Hi, I am your personal assistant. How can I help you?\"),\n",
    "        HumanMessage(content=\"I would like to book a flight to Paris.\"),\n",
    "        AIMessage(content=\"Sure, when would you like to travel?\"),\n",
    "        HumanMessage(content=\"Next week.\"),\n",
    "        AIMessage(content=\"Great, I found a flight for you. Do you want to book it?\"),\n",
    "        HumanMessage(content=\"Yes, please.\"),\n",
    "        AIMessage(content=\"Done. Your flight is booked.\")\n",
    "    ],\n",
    "    num_sentences=2\n",
    ")\n",
    "print(chat_prompt_value.to_string())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "langchain_snippets",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
